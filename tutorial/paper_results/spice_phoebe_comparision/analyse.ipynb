{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02371ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91650e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mesh = 20000\n",
    "PATH1 = f'scr_mk27/eclipse_grid_{n_mesh}'\n",
    "PATH2 = f'scr_mk27/eclipse_grid_{n_mesh}_vbig'\n",
    "PATH3 = f'scr_mk27/eclipse_grid_{n_mesh}_big'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218b2793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3292\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files_in_path = [os.path.join(PATH1, fname) for fname in os.listdir(PATH1) if fname.endswith('.pkl') or fname.endswith('.pickle')] \\\n",
    "    + \\\n",
    "    [os.path.join(PATH2, fname) for fname in os.listdir(PATH2) if fname.endswith('.pkl') or fname.endswith('.pickle')] + \\\n",
    "    [os.path.join(PATH3, fname) for fname in os.listdir(PATH3) if fname.endswith('.pkl') or fname.endswith('.pickle')]\n",
    "\n",
    "print(len(files_in_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3997e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3292/3292 [31:29<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import mmap\n",
    "\n",
    "ln10 = np.log(10)\n",
    "_SCALAR_TYPES = (int, float, str, np.number)\n",
    "\n",
    "def fast_load(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "        return pickle.loads(mm)\n",
    "\n",
    "def process_pickle_file(pkfile):\n",
    "    try:\n",
    "        data = fast_load(pkfile)\n",
    "\n",
    "        flux = data.get(\"fluxes_phoebe\")\n",
    "        bol  = data.get(\"bol_lum\")\n",
    "\n",
    "        # Fast in-place-ish transform\n",
    "        logs = np.log(flux)\n",
    "        logs /= ln10\n",
    "        fluxes = -2.5 * logs\n",
    "\n",
    "        f0 = fluxes[0]\n",
    "        b0 = bol[0]\n",
    "        metric = np.abs((fluxes - f0) - (bol - b0))\n",
    "\n",
    "        scalars = {\n",
    "            k: v for k, v in data.items()\n",
    "            if isinstance(v, _SCALAR_TYPES)\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            \"fluxes\": fluxes,\n",
    "            \"metric\": metric,\n",
    "            **scalars,\n",
    "        }, None\n",
    "\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "results = [process_pickle_file(f) for f in tqdm(files_in_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6720a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluxes and metric saved to: scr_mk27/fluxes_and_metric_20000.parquet\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "# Filter out None results\n",
    "flux_metric_records = [r for r, err in results if r is not None]\n",
    "if flux_metric_records:\n",
    "    # Find largest mesh size (if applicable, else arbitrary value)\n",
    "    n_mesh = max((r.get('n_mesh', 0) for r in flux_metric_records), default=0)\n",
    "    # Convert to pyarrow Table\n",
    "    def convert_to_arrow_table(recs):\n",
    "        # Find the longest arrays for fluxes/metric for padding\n",
    "        max_flux_len = max((len(r['fluxes']) for r in recs), default=0)\n",
    "        max_metric_len = max((len(r['metric']) for r in recs), default=0)\n",
    "        fluxarr = []\n",
    "        metricarr = []\n",
    "        # Collect all parameter keys except 'fluxes', 'metric'\n",
    "        param_keys = set()\n",
    "        for r in recs:\n",
    "            param_keys.update(\n",
    "                k for k in r.keys() if k not in ('fluxes', 'metric') and isinstance(r[k], (int, float, str, np.integer, np.floating))\n",
    "            )\n",
    "\n",
    "        param_dict = {k: [] for k in param_keys}\n",
    "        for r in recs:\n",
    "            # Pad arrays to common length\n",
    "            fluxvec = np.asarray(r['fluxes'])\n",
    "            metvec = np.asarray(r['metric'])\n",
    "            if fluxvec.shape[0] < max_flux_len:\n",
    "                fluxvec = np.pad(fluxvec, (0, max_flux_len - fluxvec.shape[0]), constant_values=np.nan)\n",
    "            if metvec.shape[0] < max_metric_len:\n",
    "                metvec = np.pad(metvec, (0, max_metric_len - metvec.shape[0]), constant_values=np.nan)\n",
    "            fluxarr.append(fluxvec)\n",
    "            metricarr.append(metvec)\n",
    "            # For each parameter, pull value if present, else np.nan or ''\n",
    "            for k in param_keys:\n",
    "                v = r.get(k, np.nan if k not in ('file',) else \"\")\n",
    "                param_dict[k].append(v)\n",
    "\n",
    "        arrays = {\n",
    "            'fluxes': fluxarr,\n",
    "            'metric': metricarr\n",
    "        }\n",
    "        # Add all parameters except filename (do not include basename or file path)\n",
    "        arrays.update(param_dict)\n",
    "        tbl = pa.table(arrays)\n",
    "        return tbl\n",
    "\n",
    "    tbl = convert_to_arrow_table(flux_metric_records)\n",
    "    parquet_path = os.path.join('scr_mk27', f\"fluxes_and_metric_20000.parquet\")\n",
    "    pq.write_table(tbl, parquet_path)\n",
    "    print(\"Fluxes and metric saved to:\", parquet_path)\n",
    "else:\n",
    "    print(\"No valid records to save to parquet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f2435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluxes and metric saved to: scr_mk27/fluxes_and_metric_5000.parquet\n"
     ]
    }
   ],
   "source": [
    "# Prepare and save as parquet: fluxes and metric may be arrays, so use pyarrow Table\n",
    "# Convert lists of dicts to pyarrow Table\n",
    "def convert_to_arrow_table(recs):\n",
    "    # Find the longest arrays for fluxes/metric for padding\n",
    "    max_flux_len = max((len(r['fluxes']) for r in recs), default=0)\n",
    "    max_metric_len = max((len(r['metric']) for r in recs), default=0)\n",
    "    fluxarr = []\n",
    "    metricarr = []\n",
    "    # Collect all parameter keys except 'fluxes', 'metric'\n",
    "    param_keys = set()\n",
    "    for r in recs:\n",
    "        param_keys.update(\n",
    "            k for k in r.keys() if k not in ('fluxes', 'metric') and isinstance(r[k], (int, float, str, np.integer, np.floating))\n",
    "        )\n",
    "\n",
    "    param_dict = {k: [] for k in param_keys}\n",
    "    for r in recs:\n",
    "        # Pad arrays to common length\n",
    "        fluxvec = np.asarray(r['fluxes'])\n",
    "        metvec = np.asarray(r['metric'])\n",
    "        if fluxvec.shape[0] < max_flux_len:\n",
    "            fluxvec = np.pad(fluxvec, (0, max_flux_len - fluxvec.shape[0]), constant_values=np.nan)\n",
    "        if metvec.shape[0] < max_metric_len:\n",
    "            metvec = np.pad(metvec, (0, max_metric_len - metvec.shape[0]), constant_values=np.nan)\n",
    "        fluxarr.append(fluxvec)\n",
    "        metricarr.append(metvec)\n",
    "        # For each parameter, pull value if present, else np.nan or ''\n",
    "        for k in param_keys:\n",
    "            v = r.get(k, np.nan if k not in ('file',) else \"\")\n",
    "            param_dict[k].append(v)\n",
    "\n",
    "    arrays = {\n",
    "        'fluxes': fluxarr,\n",
    "        'metric': metricarr\n",
    "    }\n",
    "    # Add all parameters except filename (do not include basename or file path)\n",
    "    arrays.update(param_dict)\n",
    "    tbl = pa.table(arrays)\n",
    "    return tbl\n",
    "\n",
    "tbl = convert_to_arrow_table(flux_metric_records)\n",
    "parquet_path = os.path.join('scr_mk27', f\"fluxes_and_metric_{n_mesh}.parquet\")\n",
    "pq.write_table(tbl, parquet_path)\n",
    "\n",
    "\n",
    "print(\"Fluxes and metric saved to:\", parquet_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "astro"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
